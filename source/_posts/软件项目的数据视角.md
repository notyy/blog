title: 软件项目的数据视角
date: 2015-06-24 21:42:03
tags:
- 数据
categories:
- 技术
---
![](http://7u2h31.com1.z0.glb.clouddn.com/应用层.png)

这是我几年前写的关于架构设计的文章中的一幅图，追加了一个**数据视角**。

现在大数据很火，我也在公司断续的搞了两年大数据，在spark上积累了一些经验，但是感觉现在只要提到大数据，言必称hadoop、spark等分布式计算技术，导致很多对大数据感兴趣的人面对手头不到一两G的*小数据*汪洋兴叹，好像找不到**大数据项目**就进不了大数据领域的门。

但其实大数据本质依然是数据处理、数据分析，现在的各种新技术和大数据平台都在试图屏蔽掉**大**的部分，让数据工程师（主要着重与数据处理）和数据科学家（主要着重于数据分析）能够更专注于其业务而不是专注于分布式计算平台的技术细节。

在我看来，比掌握hadoop和spark等技术更重要的是掌握基本的数据处理和分析技术（主要来自统计学领域），培养数据驱动业务的sense，能够在日常的软件开发中识别出应用数据技能的场景。 而且从现在的大趋势看来，这个要求不仅仅限于软件工程师，而是企业中的所有人，只要手头的任务存在”决策“的部分，都应该掌握这些基本技能。

就我们推崇的精益创业来说，猜想 -> 实验 -> 验证 的循环无不需要数据技能的参与。

因此，与其寻找专门的**大数据项目**，不如在手头的项目中寻找**数据部分** 。 想想手头多少项目是先*交付功能*，过很久之后再发起一个”报表系统“的项目来补这一块，而且由于缺乏数据技能，一般补得也不系统。
本文希望能促使更多人学习统计学，学习数据处理和分析的基本技能，当数据量确实大到单机无法处理的时候再求助于分布式计算平台的支撑。让数据技术成为人人必学的基本技术。

顺便提一句，如果想小数据、大数据两不误，你可以用spark本地模式来学习和处理本地文件，很方便的哦~
